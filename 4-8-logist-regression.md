# 关于逻辑回归
是用来估算一个实例属于某个特定类别的概率，超过50%则属于该类别，否则不属于该类别。
 
 * 逻辑回归一般有两种：Discriminative和Generative，前者的参数为w和b，后者的参数为μ和σ（模型可以自由选择，一般选用正态分布）  

 * 效果一般是前者好，后者的好处是有脑补的特性，不需要太多的训练数据，对噪声不敏感，前置条件是变量之间相互独立。 
  
* 逻辑回归中的损失函数即为交叉熵（用来形容两个分布之间的接近程度，当一模一样时，交叉熵为0）
* 当遇到multi-classfication时，使用softmax多元逻辑回归来操作。